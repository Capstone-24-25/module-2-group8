Our primary task was to develop a binary classification model to predict whether or not a webpage has useful information on it, and also a multi-class prediction model to predict the sort of information that would be present on a webpage. For our data preprocessing, we parse our data using the parse_data() function which cleans our data frame and produces a new column text_clean of just our clean text. parse_data() uses the parse_fn() function that processes our raw HTML and converts it to clean text. We edited the provided version of parse_fn() to also include the header elements. parse_fn() also does a series of string cleaning processes to output clean usable text. Lastly, we tokenize using the nlp_fn() function to split the cleaned text into individual word tokens. We also remove stopwords like “the” or “and” etcetera, since these words are much too common in English and are not useful for modeling. The last notable part of our preprocessing is computing a tf-idf for each token that highlights words which are important in specific documents but not necessarily across the whole data set. This tf-idf is helpful to identify keywords that may indicate a certain class or another.

As for the binary model, we were not able to improve further upon our task 2 model. As mentioned before, this model has an accuracy of .81, a sensitivity of .695, specificity of .910, and AUC of .909. We also experimented with a support vector machine that took in bigram data as well as a support vector machine that took in trigram data. Neither of these support vector machines were able to perform better than our task 2 model, and so these were not included. 

As for the multiclass model, we adapted our task 2 model. Firstly, we ran a multinomial regression on our word token data, extracted the resulting predicted probabilities for each class, and then fed these in as predictores into another regularized logistic regression model. The other predictors of this logistic regression model were bigram tf-idfs. This model has an accuracy of .800, a sensitivity of .665, and a specificity of .936. Observing our specificity of .936, we find that our model is very good at classifying when a webpage is not part of a specific class. 93.6% of the time that it categorizes a webpage as not a given class, it is correct. Unfortunately, we do continue the trend of a somewhat lackluster sensitivity. Only 66.5% of the time that our model categorizes a webpage in a given class, it is truly in that class. As for overall accuracy of 80%, I’d argue this is pretty good. 80% of the time our model correctly classifies webpages. 
